{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VxIdB7ktv0-"
   },
   "source": [
    "# Visual Analytics - Gummistiefel B\n",
    "\n",
    "# Gruppe A\n",
    "\n",
    "Phuc Tran Truong (558919)\n",
    "\n",
    "Dennis Radtke (558896)\n",
    "\n",
    "Arvid Matthes (558911)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVF6AW5JUpre"
   },
   "source": [
    "## 1. Aufgabenstellung & Überblick\n",
    "\n",
    "Gummistiefel-Projekte\n",
    "Daten:\n",
    "Die Daten werden durch einen Webservice bereitgestellt. Dieser ist unter folgender URL erreichbar:\n",
    "\n",
    "http://rz-vm154.gfz-potsdam.de:8080/highprecip/events/\n",
    "\n",
    "Es gibt 2 Arten von Anfragen:\n",
    "1. query: Rückgabe aller Ereignisse, welche innerhalb der gegebenen Parameterlimits liegen. Zur Einschränkung können alle Parameter des Ereignisses verwendet werden. Beispiele: id,\n",
    "start, size, area, ... Des weiteren kann auch räumlich mithilfe des 'intersects' Befehls und\n",
    "eines Polygons im WKT Format (well-known text) gefiltert werden.\n",
    "2. get: (+ id) eines Ereignisses gibt die Ereignisdaten einschließlich der Ereigniszeitreihe\n",
    "zurück. \n",
    "\n",
    "Beispiele:\n",
    "- http://rz-vm154.gfz-potsdam.de:8080/highprecip/events/get?id=201600043\n",
    "- http://rz-vm154.gfz-potsdam.de:8080/highprecip/events/get?id=201600043&format=geojson\n",
    "- http://rz-vm154.gfz-potsdam.de:8080/highprecip/events/query?subset=length(20,100)&subset=si(0.1,0.3)&subset=area(2,5)\n",
    "- http://rz-vm154.gfz-potsdam.de:8080/highprecip/events/query?subset=intersects(POLYGON ((11 53,15 53,15 51,11 51, 11 53)))&subset=area(1.0,10)\n",
    "\n",
    "### Fragestellung B: Untersuchung der zeitlichen Entwicklung von Starkregenereignissen\n",
    "Gegeben sind Starkregenereignisse der Jahre 1979-2017 für ein Gebiet, welches Deutschland, die Schweiz und Italien umfasst. Wissenschaftlerin Caliga interessiert sich für die Veränderung der Starkregenereignisse über die Zeit. Sie möchte Veränderungen der Eigenschaften der Starkregenereignisse untersuchen und mögliche Trends identifizieren. Welche konkreten Zeitintervalle dafür zusammengefasst werden müssen, kann nicht pauschal festgelegt werden. Für definierte Zeitintervalle möchte sie einen Überblick über die Eigenschaften der Starkregenereignisse bekommen. Als globale Referenz sollen die Eigenschaften der Starkregenereignisse über den gesamten Zeitraum herangezogen werden. Für eine eingehende Untersuchung möchte Caliga zwei der definierten Zeitintervalle detailliert vergleichen. Für diesen Detailvergleich sind einzelne, besonders extreme Ereignisse relevant, bspw. das zeitlich längste, das intensivste oder räumlich ausgedehnteste Ereignis. Zur abschließenden Bewertung möchte sie die raum-zeitliche Entwicklung dieser gewählten Extremereignisse ebenfalls untersuchen und vergleichen.\n",
    "\n",
    "### Zusammenfassung:\n",
    "Priorität: Zeitliche Entwicklung (nicht regionale Unterschiede)\n",
    "\n",
    "Forscher:\tCaliga\n",
    "\n",
    "Wetter:\t\tStarkregenereignisse\n",
    "\n",
    "Gebiet:\t\tDeutschland, Italien, Schweiz\n",
    "\n",
    "Zeitraum:\t1979-2017 \n",
    "\n",
    "Hypothese:\tEs existieren Trends bei Starkregenereignissen\n",
    "\n",
    "Hypothese:\tEs existieren (zeitliche) Veränderungen der Eigenschaften des Starkregens\n",
    "\n",
    "Aufgabe:\tvergleiche 2 definierte Zeitintervalle detailliert\n",
    "\n",
    "Aufgabe:\tvergleiche/ untersuche raum-zeitliche Entwicklung\n",
    "\n",
    "Tipps:\t\t- fasse bestimmte Zeitintervalle zusammen\n",
    "\n",
    " -ermittle extreme Ereignisse im Hinblick auf: lange Zeitdauer, Intensität, großer Raum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mI7-Bl2mT4P1"
   },
   "source": [
    "## 2. Datenexploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx7fz88nXYsl"
   },
   "source": [
    "###2.1. Einlesen der Daten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDX0HRF92anE",
    "outputId": "41d11433-ec1c-4cb8-9341-9544c5389140"
   },
   "outputs": [],
   "source": [
    "# Notwendige Bibliotheken installieren:\n",
    "!pip install asyncio aiohttp nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MED0k341tP6C"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import nest_asyncio \n",
    "from typing import Dict, List, Union, Optional\n",
    "\n",
    "nest_asyncio.apply()  # fixes bugs with event loops and jupyter notebooks\n",
    "\n",
    "gummistiefel_server = \"http://rz-vm154.gfz-potsdam.de:8080/highprecip/events/\"\n",
    "\n",
    "\n",
    "async def download_site(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.read()\n",
    "\n",
    "\n",
    "async def download_all_sites(sites):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in sites:\n",
    "            task = asyncio.ensure_future(download_site(url, session))\n",
    "            tasks.append(task)\n",
    "        return await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "\n",
    "def get_event_url(event_id: Union[str, int], \n",
    "                    webserver_address: str = gummistiefel_server,\n",
    "                    geojson: bool = True) -> str:\n",
    "    url = webserver_address + \"get?id=\" + str(event_id)\n",
    "    if geojson:\n",
    "        url += \"&format=geojson\" \n",
    "    return url\n",
    "\n",
    "\n",
    "def get_event(event_id: Union[str, int], \n",
    "                    webserver_address: str = gummistiefel_server,\n",
    "                    geojson: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "        Takes an id and retrieves the corresponding precipiation event from\n",
    "        the web server. Simple implementation with requests for single event \n",
    "        retrieval.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        event_id: Document containing events\n",
    "        webserver_address: Address of the web server\n",
    "        geojson: Whether to request in geojson format\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Event as json dictionary\n",
    "    \"\"\"\n",
    "    url = get_event_url(event_id, webserver_address, geojson)\n",
    "    f = requests.get(url) # TODO handle invalid urls\n",
    "    json_dict = json.loads(f.text)\n",
    "    return json_dict\n",
    "\n",
    "\n",
    "def get_events(event_ids: List[Union[str, int]],\n",
    "               webserver_address: str = gummistiefel_server,\n",
    "                geojson: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "        Takes a list of event ids and retrieves the corresponding precipiation events \n",
    "        from the web server. Uses asyncio, aiohttp stuff for faster asynchronous\n",
    "        retrieval.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        query: String query\n",
    "        webserver_address: Address of the web server\n",
    "        geojson: Whether to request in geojson format\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Events as a list of json dictionaries\n",
    "    \"\"\"\n",
    "    urls = [get_event_url(event_id, webserver_address, geojson) for event_id in event_ids]\n",
    "    loop = asyncio.get_event_loop()\n",
    "    events = loop.run_until_complete(download_all_sites(urls))\n",
    "    return [json.loads(event) for event in events]\n",
    "\n",
    "\n",
    "def query_events(query: str, \n",
    "                 webserver_address: str = gummistiefel_server,\n",
    "                 geojson: bool = True,\n",
    "                 with_time_series: bool = True) -> List[Dict]:\n",
    "    \"\"\"\n",
    "        Takes a string query and retrieves the corresponding precipiation events \n",
    "        from the web server.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        query: String query\n",
    "        webserver_address: Address of the web server\n",
    "        geojson: Whether to request in geojson format\n",
    "        with_time_series: Whether to send get requests for each event to retrieve time series data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Events as a list of json dictionaries\n",
    "    \"\"\"\n",
    "    url = webserver_address + \"query?\" + query\n",
    "    f = requests.get(url) # TODO handle invalid urls\n",
    "    json_dict = json.loads(f.text)\n",
    "    if with_time_series:\n",
    "        event_ids = [event[\"id\"] for event in json_dict]\n",
    "        return get_events(event_ids, webserver_address, geojson)\n",
    "    else:\n",
    "        return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kc8gDUo9wXP6",
    "outputId": "41eebba9-6337-44dc-8586-e73c249b6598"
   },
   "outputs": [],
   "source": [
    "# Beispiel Get-Abfrage eines Ereignisses:\n",
    "\n",
    "event_id = 201600043\n",
    "event = get_event(event_id, geojson=True)\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "VAsEgjwbwmSM",
    "outputId": "03d06abf-23e2-492d-ca64-7b10d653d1bf"
   },
   "outputs": [],
   "source": [
    "# Beispiel Query-Abfrage zu Ereignissen mit gegebenen Parametern:\n",
    "\n",
    "query = \"subset=length(20,100)&subset=si(0.1,0.3)&subset=area(2,5)\"\n",
    "events = query_events(query, geojson=True)\n",
    "pd.DataFrame(events).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIFf9WxYc-EM"
   },
   "source": [
    "##2.2. Erläuterungen zu Variablen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-dcH3pNJUAa"
   },
   "source": [
    "### 2.3. Plotting\n",
    "\n",
    "Pakete zur Verarbeitung/ Analyse von Geodaten suchen und anwenden.\n",
    "z.B.:\n",
    "- https://www.twilio.com/blog/2017/08/geospatial-analysis-python-geojson-geopandas.html\n",
    "\n",
    "Man kann die Daten im GeoJSON Format herunterladen. Dazu gibt es dann Pakete wie geojson. Mit geopandas kann man scheinbar besser mit geografischen Daten arbeiten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lr4VvXxzuVur"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9ePBYAonyLY"
   },
   "source": [
    "Eine Zeitreihe von einem Event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "Dxga-UvuntbZ",
    "outputId": "9961d1c6-e911-4198-be4d-b8a87e62d9c6"
   },
   "outputs": [],
   "source": [
    "# Ereignisezeitreihe vom 24./25.07.1981 (20 Ereignisse):\n",
    "\n",
    "event_id = 198103100\n",
    "event = get_event(event_id, geojson=False)\n",
    "\n",
    "time_series = pd.DataFrame(event['timeseries'])\n",
    "_ = sns.relplot(\n",
    "    x='lon',\n",
    "    y='lat',\n",
    "    size='si',\n",
    "    data=time_series\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ-ZMOdnn3g_"
   },
   "source": [
    "Alle Events in einem bestimmten Zeitraum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KV6_R7Fpn9EO"
   },
   "outputs": [],
   "source": [
    "#query = \"subset=start(1982-11-01T02:00:00,1982-12-01T02:00:00)\"\n",
    "query = \"subset=length(20,100)&subset=si(0.1,0.3)&subset=area(2,5)\"\n",
    "events = query_events(query, geojson=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVhSZwHooACq"
   },
   "outputs": [],
   "source": [
    "# neue Variable \"year\" für Darsatellung der timeseries-Parameter:\n",
    "\n",
    "precip_events_list = pd.DataFrame(events)['timeseries'].tolist()\n",
    "precip_events = [\n",
    "    time_series_element  for precip_event in precip_events_list for time_series_element in precip_event\n",
    "]\n",
    "years = [int(precip_event['date'][:4]) for precip_event in precip_events]\n",
    "precip_events_df = pd.DataFrame(precip_events)\n",
    "precip_events_df['year'] = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "_Hxbj66pfGJ3",
    "outputId": "f9ed648c-6191-40cf-866b-bafcdf4525ab"
   },
   "outputs": [],
   "source": [
    "precip_events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "wezikIrXoLfE",
    "outputId": "755d1104-3a14-46ab-df6f-ebd9eab087c9"
   },
   "outputs": [],
   "source": [
    "_ = sns.relplot(\n",
    "    x='lon',\n",
    "    y='lat',\n",
    "    hue='year',\n",
    "    size='si',\n",
    "    sizes=(10,200),\n",
    "    alpha=0.5,\n",
    "    palette=\"viridis\",\n",
    "    data=precip_events_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "0urlL_NmfKqi",
    "outputId": "824b4d19-fcf1-4045-9071-52204378839d"
   },
   "outputs": [],
   "source": [
    "_ = sns.relplot(\n",
    "    x='lon',\n",
    "    y='lat',\n",
    "    hue='year',\n",
    "    size='meanPre',\n",
    "    sizes=(10,200),\n",
    "    alpha=0.5,\n",
    "    palette=\"viridis\",\n",
    "    data=precip_events_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax900F_YoNcR"
   },
   "source": [
    "Idealerweise würde man das irgendwie auf eine Landkarte malen, um eine Wetterkarte zu kriegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "KFhik4kTfPEV",
    "outputId": "00b49e1e-83c5-4184-be15-eed92cfed663"
   },
   "outputs": [],
   "source": [
    "_ = sns.boxplot(x=precip_events_df['meanPre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwgDWnDO4BcP"
   },
   "source": [
    "Ideen:\n",
    "- Länderkarte einbinden & Daten darauf anzeigen lassen\n",
    "- Alle Ereignisse mit allen Zeitreihen in einer Matrix speichern(?) Alternative?\n",
    "   -> Ziel: Extrema ermitteln; \"Starkregen\" ermitteln (Ort, Zeit, Intensität)\n",
    "   -> weglassen Daten die nicht in GER/IT/CHE liegen?\n",
    "- Korrelationsmatrix zwischen si und length (sollten stark positiv korreliert sein..)\n",
    "- 201706105 Extremwert... gibt viele Informationen relativ zu Ereigniszeitpunkten\n",
    "- Äpfel & Birnen: geänderte Messbedingungen in Daten sichtbar?\n",
    "- Varianz = stdv²\n",
    "- tiefere Recherche Geoinformatik & QGis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTHJTmbNhS8B"
   },
   "source": [
    "## 2.4. Daten-Mapping\n",
    "\n",
    "Georeferenz nach EPSG 4326 (\n",
    "European Petroleum Survey Group Geodesy) i.V.m. ISO 19111 & WGS 84.\n",
    "\n",
    "Mögliche Software hierfür: QGis ?\n",
    "\n",
    "Siehe [EPSG3] für Überblick der Längen- & Breitengrade im Format (x=lon; y=lat) mit lon = Longitude & lat = Latitude\n",
    "\n",
    "in [Umrechnung] lassen sich Koordinatendaten umrechnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeSP2K-TRpH2"
   },
   "source": [
    "https://towardsdatascience.com/a-complete-guide-to-an-interactive-geographical-map-using-python-f4c5197e23e0\n",
    "\n",
    "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/04.13-Geographic-Data-With-Basemap.ipynb#scrollTo=9mk5YrjXRxMP\n",
    "\n",
    "https://thedatafrog.com/en/articles/show-data-google-map-python/\n",
    "\n",
    "am besten Datensätze einblenden auf der bekannten Google Map? (3. Link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3bEmDwZgMzD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjyT-1K3gQq9"
   },
   "source": [
    "## 2.5. Zeitliche Betrachtungen\n",
    "\n",
    "- zeitlicher Verlauf eines Ereignisses\n",
    "- Unterschiede monatlich/ wöchentlich/ jährlich/ täglich\n",
    "- betrachtung Quartalweise/ Semester/ Trimester\n",
    "- si werte im Zeitverlauf eines Ereignisses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pv-VmRRlnuqA"
   },
   "source": [
    "## 2.6. Gesamtbetrachtung der Daten\n",
    "Wie erhält man alle Daten? \n",
    "Weiß nicht, ob man das noch in Colab hinbekommt, weil die Session wahrscheinlich irgendwann nach einem Timeout beendet wird.\n",
    "Daher eher mit einem Jupyter Notebook lokal oder noch besser ein Python Skript schreiben und auch lokal ausführen.\n",
    "\n",
    "1.   Query (/Queries) verfassen, die alle Events umfassen, vielleicht in Monats oder Jahresschritten\n",
    "2.   Als Json Datei auf lokales System schreiben\n",
    "\n",
    "Mit `pandas` geht das Abspeichern relativ einfach, wenn man die Daten schon in eine `pandas.DataFrame` gepackt hat: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xghmQNc_IrBy"
   },
   "source": [
    "Problem:\n",
    "wenn ich im Code unten alle Datensätze von 1979 wähle (00001 bis 99999) erhalte ich den Fehlercode:\n",
    "\n",
    "*TypeError: the JSON object must be str, bytes or bytearray, not TimeoutError*\n",
    "\n",
    "Bei 00001 bis 05000 bspw. kommt der Fehler (noch) nicht.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QG1-VixJIAJ3"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "y0 = \"1979\"\n",
    "y1 = \"1979\"\n",
    "d0 = \"00001\"\n",
    "d1 = \"00100\"\n",
    "\n",
    "d0int = int(d0)\n",
    "d1int = int(d1)\n",
    "\n",
    "# Misst Startzeit\n",
    "start = time.time()\n",
    "\n",
    "query = \"subset=id({}{},{}{})\".format(y0,d0,y1,d1)\n",
    "events = query_events(query, geojson=True)\n",
    "df = pd.DataFrame(events)\n",
    "\n",
    "# Struktureller Überblick\n",
    "#print(df.head())\n",
    "\n",
    "# Überblick Speicher\n",
    "#print(df.info())\n",
    "\n",
    "# Misst Endzeit\n",
    "end = time.time()\n",
    "\n",
    "# Datensätze aus ca. einem halben Jahr dauern bei mir lokal ca. 4min mittels Spyder \n",
    "print( \"Es wurden\", d1int - d0int + 1, \"IDs abgefragt in\", round(end - start, 2), \"Sekunden bzw.\", round((end - start)/60,2), \"Minute(n)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z7j3DLNYL9q"
   },
   "source": [
    "## 3. Interaktivität"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaicFwf6YPfn"
   },
   "source": [
    "###3.1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4SGw3NXUMeL"
   },
   "source": [
    "## 4. Quellen:\n",
    "[Python] https://requests.readthedocs.io/en/master/user/quickstart/#response-content (11.11.2020 20:31*)\n",
    "\n",
    "[Python2] https://realpython.com/python-concurrency/ (13.11.2020 19:11*)\n",
    "\n",
    "[Methode] https://nhess.copernicus.org/articles/17/1177/2017/ (17.11.2020 15:31*)\n",
    "\n",
    "[Geojson] https://www.twilio.com/blog/2017/08/geospatial-analysis-python-geojson-geopandas.html (22.11.2020 10:16*)\n",
    "\n",
    "[EPSG] https://gisisit.wordpress.com/2013/12/03/epsg-codes-fur-deutschland/ (23.11.2020 15:12*)\n",
    "\n",
    "[EPSG2] https://de.wikipedia.org/wiki/Koordinatenreferenzsystem (23.11.2020 15:18*)\n",
    "\n",
    "[EPSG3] https://epsg.io/map#srs=4326&x=0.000000&y=0.000000&z=1&layer=streets (23.11.2020 17:29*)\n",
    "\n",
    "[Umrechnung] https://www.kompf.de/trekka/geoposition.php (23.11.2020 17:51*)\n",
    "\n",
    "[EPSG4] https://spatialreference.org/ref/epsg/wgs-84/ (23.11.2020 17:58*)\n",
    "\n",
    "[Polygon] https://de.wikipedia.org/wiki/Simple_Feature_Access (24.11.2020 09:37*)\n",
    "\n",
    "[Polygon2] https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry (24.11.2020 10:08*)\n",
    "\n",
    "\n",
    "#####* Datum & Uhrzeit des letzten Zugriffs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VisualAnalytics-Datenexploration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (visualanalytics)",
   "language": "python",
   "name": "visualanalytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
